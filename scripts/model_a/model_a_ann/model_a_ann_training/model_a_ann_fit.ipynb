{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1314772-f552-4cc6-9c2a-a2b6b56c284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras import models, layers, regularizers, optimizers, callbacks, utils, losses, metrics\n",
    "# from keras.metrics import BinaryAccuracy, AUC, BinaryCrossentropy\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow import convert_to_tensor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# utils.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97cf9ac4-36af-4575-baf6-6fb382429fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/model_a_training'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker'\n",
    "dir_working_model_a_training = os.path.join(data_dir, 'working_data/model_a/model_a_training')\n",
    "dir_working_model_a_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b74e82b6-0775-49fc-a6c5-4593f096af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_x_1_a_out = os.path.join(data_dir, 'working_data/model_second_stage/model_second_stage_training/temp/x_1_a.parquet')\n",
    "fn_y_fit_1_a_ann = os.path.join(data_dir, 'working_data/model_second_stage/model_second_stage_training/temp/y_fit_1_a_ann.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0256714-d5e0-446f-ad0e-eed57eea252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_x = os.path.join(dir_working_model_a_training, 'x.parquet')\n",
    "fn_y = os.path.join(dir_working_model_a_training, 'y.parquet')\n",
    "fn_id = os.path.join(dir_working_model_a_training, 'id.parquet')\n",
    "\n",
    "fn_model = os.path.join(dir_working_model_a_training, 'model_a_ann.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ec06f5-0908-429f-976a-723403452726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dropout_1': 0.00012044868222029, 'dropout_2': 0.0632962786094702, 'relu_1': 33, 'relu_2': 20, 'epochs': 20}\n"
     ]
    }
   ],
   "source": [
    "fn_params = os.path.join(dir_working_model_a_training, 'model_a_ann_hp.csv')\n",
    "params = pd.read_csv(fn_params).to_dict(orient='list')\n",
    "params = {k:params[k][0] for k in params.keys()}\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd296791-e5b1-4306-87f0-c3b08706e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_cleaning(X):\n",
    "    X = np.clip(X, a_min=-3, a_max=3)\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd76000-134c-409d-944b-0fc9c5aba83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_parquet(fn_x)\n",
    "Y = pd.read_parquet(fn_y)\n",
    "ID = pd.read_parquet(fn_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7480c804-69d7-4121-8a2f-d20fff85a5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all done automagically by the R script that creates the new data tranches.\n",
    "# We only need to do this for the final model training\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X)\n",
    "XClean = standard_scaler.transform(X)\n",
    "XClean = np_cleaning(XClean)\n",
    "\n",
    "pd.DataFrame(XClean).to_parquet(fn_x_1_a_out)\n",
    "\n",
    "XClean = convert_to_tensor(XClean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eefb952-ba3c-4460-8ee1-62926ec8b346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 410us/step - auc: 0.9200 - binary_accuracy: 0.9993 - binary_crossentropy: 0.0041 - loss: 0.0041\n",
      "Epoch 2/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 400us/step - auc: 0.9577 - binary_accuracy: 0.9997 - binary_crossentropy: 0.0018 - loss: 0.0018\n",
      "Epoch 3/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 395us/step - auc: 0.9635 - binary_accuracy: 0.9997 - binary_crossentropy: 0.0017 - loss: 0.0017\n",
      "Epoch 4/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 406us/step - auc: 0.9711 - binary_accuracy: 0.9997 - binary_crossentropy: 0.0015 - loss: 0.0015\n",
      "Epoch 5/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 432us/step - auc: 0.9728 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0013 - loss: 0.0013\n",
      "Epoch 6/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 413us/step - auc: 0.9760 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0012 - loss: 0.0012\n",
      "Epoch 7/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 391us/step - auc: 0.9746 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0012 - loss: 0.0012\n",
      "Epoch 8/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 387us/step - auc: 0.9759 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0012 - loss: 0.0012\n",
      "Epoch 9/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 389us/step - auc: 0.9771 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0011 - loss: 0.0011\n",
      "Epoch 10/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 390us/step - auc: 0.9760 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0012 - loss: 0.0012\n",
      "Epoch 11/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 391us/step - auc: 0.9764 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0011 - loss: 0.0011\n",
      "Epoch 12/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 391us/step - auc: 0.9772 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0012 - loss: 0.0012\n",
      "Epoch 13/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 392us/step - auc: 0.9795 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0011 - loss: 0.0011\n",
      "Epoch 14/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 392us/step - auc: 0.9752 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0012 - loss: 0.0012\n",
      "Epoch 15/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 393us/step - auc: 0.9756 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0012 - loss: 0.0012\n",
      "Epoch 16/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 394us/step - auc: 0.9753 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0011 - loss: 0.0011\n",
      "Epoch 17/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 394us/step - auc: 0.9777 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0011 - loss: 0.0011\n",
      "Epoch 18/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 397us/step - auc: 0.9753 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0011 - loss: 0.0011\n",
      "Epoch 19/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 400us/step - auc: 0.9764 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0012 - loss: 0.0012\n",
      "Epoch 20/20\n",
      "\u001b[1m49800/49800\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 400us/step - auc: 0.9783 - binary_accuracy: 0.9998 - binary_crossentropy: 0.0012 - loss: 0.0012\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dropout(rate=params[\"dropout_1\"]))\n",
    "model.add(layers.Dense(units=int(params[\"relu_1\"]), activation='relu'))    \n",
    "model.add(layers.Dropout(rate=params[\"dropout_2\"]))\n",
    "model.add(layers.Dense(units=int(params[\"relu_2\"]), activation='relu'))   \n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(\n",
    "    loss=losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        metrics.BinaryCrossentropy(),\n",
    "        metrics.BinaryAccuracy(), \n",
    "        metrics.AUC()\n",
    "    ]\n",
    ")\n",
    "    \n",
    "history = model.fit(\n",
    "    XClean, Y, epochs=int(params['epochs']), batch_size=128,  # hard-coded here\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c72de505-e017-4edb-b7ad-5fd86620fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(fn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdb99213-fdfb-4a5a-b406-48a7b1f169a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m199199/199199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 196us/step\n"
     ]
    }
   ],
   "source": [
    "y_fit = model.predict(XClean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83f82fa9-987a-4c6f-b760-410434667865",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(y_fit).rename(columns={0:'y_fit_1_a_ann'}).to_parquet(fn_y_fit_1_a_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe44c436-afcb-4e85-8495-7d385b92010e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook model_a_ann_fit.ipynb to script\n",
      "[NbConvertApp] Writing 2441 bytes to model_a_ann_fit.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script model_a_ann_fit.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
