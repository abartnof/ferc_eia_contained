{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc7baf55-39ea-4bb7-8efa-f5f0c01d812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from keras import models, layers, regularizers, optimizers, callbacks, utils, losses, metrics\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow import convert_to_tensor\n",
    "\n",
    "from ray import train, tune\n",
    "from ray.tune.search.optuna import OptunaSearch\n",
    "from ray.tune.search import ConcurrencyLimiter\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tqdm import tqdm\n",
    "# from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8b0cb7f-b350-4e77-b142-10c84331efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_x = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/x.parquet'\n",
    "fn_y = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/y.parquet'\n",
    "fn_id = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/id.parquet'\n",
    "\n",
    "# dir_hyperparameters = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train'\n",
    "fn_grid = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/ann/grid_search.csv'\n",
    "fn_out = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/ann/cross_validation_of_best_candidates_ann.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db9e6d12-6880-4395-9b34-b8c908ec93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_cleaning(X):\n",
    "    X = np.clip(X, a_min=-3, a_max=3)\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c89f177-b90b-4a8d-8bf6-1cb0fb721acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_parquet(fn_x)\n",
    "Y = pd.read_parquet(fn_y)\n",
    "ID = pd.read_parquet(fn_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0396c3d7-2144-427e-9be7-000057add4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropout_1': 0.0010165143140152,\n",
       " 'dropout_2': 0.1510715157535853,\n",
       " 'relu_1': 50.0,\n",
       " 'relu_2': 27.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_dict = {'config/dropout_1':'dropout_1', 'config/dropout_2':'dropout_2', 'config/relu_1':'relu_1', 'config/relu_2':'relu_2'} #, 'config/metrics':'metrics'}\n",
    "\n",
    "Grid = pd.read_csv(fn_grid, index_col='rank')\n",
    "Grid = Grid.rename(columns=rename_dict)[list(rename_dict.values())]\n",
    "\n",
    "# Create a dictionary: punch in the rank of the model we want to use, and get the parameters back, as a dictionary\n",
    "param_dict = {i:Grid.loc[i].to_dict() for i in Grid.index}\n",
    "param_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98d5496c-94b0-4fbc-9f6d-33d5c438911d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40aa261e3ca844c9bc2feb608c8b2d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39884/39884\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 934us/step - auc: 0.8940 - binary_accuracy: 0.9992 - binary_crossentropy: 0.0047 - loss: 0.0047 - val_auc: 0.9519 - val_binary_accuracy: 0.9997 - val_binary_crossentropy: 0.0015 - val_loss: 0.0015\n",
      "\u001b[1m40064/40064\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 539us/step - auc: 0.9038 - binary_accuracy: 0.9992 - binary_crossentropy: 0.0044 - loss: 0.0044 - val_auc: 0.9622 - val_binary_accuracy: 0.9997 - val_binary_crossentropy: 0.0015 - val_loss: 0.0015\n"
     ]
    }
   ],
   "source": [
    "variables = [\n",
    "    range(15),  # num hyperparameters to test\n",
    "    range(5)  # number of folds in the ID table\n",
    "]\n",
    "\n",
    "results_list = []\n",
    "for (hp_rank, fold) in tqdm(list(itertools.product(*variables))):\n",
    "    \n",
    "    space = param_dict[hp_rank]\n",
    "    # Split data into training and validation\n",
    "    is_train_mask = (ID['fold_num'] != fold).values\n",
    "    \n",
    "    XTrain = X.loc[is_train_mask]\n",
    "    XVal = X.loc[~is_train_mask]\n",
    "    y_train = Y.loc[is_train_mask, 'is_match']\n",
    "    y_val = Y.loc[~is_train_mask, 'is_match']\n",
    "    \n",
    "    # X value processing\n",
    "    standard_scaler = StandardScaler()\n",
    "    standard_scaler.fit(XTrain)\n",
    "    XTrain = standard_scaler.transform(XTrain)\n",
    "    XVal  = standard_scaler.transform(XVal)\n",
    "    \n",
    "    XTrain = np_cleaning(XTrain)\n",
    "    XVal  = np_cleaning(XVal)\n",
    "    \n",
    "    XTrain = convert_to_tensor(XTrain)\n",
    "    XVal = convert_to_tensor(XVal)\n",
    "\n",
    "    # Fit model\n",
    "    clear_session()\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dropout(rate=space[\"dropout_1\"]))\n",
    "    model.add(layers.Dense(units=int(space[\"relu_1\"]), activation='relu'))    \n",
    "    model.add(layers.Dropout(rate=space[\"dropout_2\"]))\n",
    "    model.add(layers.Dense(units=int(space[\"relu_2\"]), activation='relu'))   \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        loss=losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            metrics.BinaryCrossentropy(),\n",
    "            metrics.BinaryAccuracy(), \n",
    "            metrics.AUC()\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "    history = model.fit(\n",
    "        XTrain, y_train, epochs=500, batch_size=128,  # hard-coded here\n",
    "        validation_data=(XVal, y_val), \n",
    "        callbacks=callbacks.EarlyStopping(patience=5, start_from_epoch=10),\n",
    "        verbose=1\n",
    "    )\n",
    "    Results = pd.DataFrame(history.history) \n",
    "    Results['hp_rank'] = hp_rank\n",
    "    Results['fold'] = fold\n",
    "    Results['epoch'] = Results.index + 1\n",
    "    results_list.append(Results)\n",
    "\n",
    "    # metric_dict = {\n",
    "    #     \"num_epochs\": len( history.history['val_binary_crossentropy'] ) - 5,  # with patience set at 5, we can just find len and subtract five\n",
    "    #     \"binary_crossentropy\": np.min(history.history['val_binary_crossentropy'][10:]),\n",
    "    #     \"auc\": np.min(history.history['val_auc'][10:]),\n",
    "    #     'binary_accuracy': np.min(history.history['val_binary_accuracy'][10:])\n",
    "    #     }\n",
    "    # Metrics = pd.DataFrame(metric_dict, index=range(1))\n",
    "    # metrics_list.append(Metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92dd746b-e854-4689-a5cf-e33744f9904d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>binary_accuracy</th>\n",
       "      <th>binary_crossentropy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>val_binary_accuracy</th>\n",
       "      <th>val_binary_crossentropy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>hp_rank</th>\n",
       "      <th>fold</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.939445</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.951857</td>\n",
       "      <td>0.999683</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.938801</td>\n",
       "      <td>0.999453</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.962167</td>\n",
       "      <td>0.999717</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0.001472</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        auc  binary_accuracy  binary_crossentropy      loss   val_auc  \\\n",
       "0  0.939445         0.999461             0.002448  0.002448  0.951857   \n",
       "1  0.938801         0.999453             0.002485  0.002485  0.962167   \n",
       "\n",
       "   val_binary_accuracy  val_binary_crossentropy  val_loss  hp_rank  fold  \\\n",
       "0             0.999683                 0.001546  0.001546        0     0   \n",
       "1             0.999717                 0.001472  0.001472        0     1   \n",
       "\n",
       "   epoch  \n",
       "0      1  \n",
       "1      1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CollectedMetrics = pd.concat(results_list)\n",
    "CollectedMetrics.reset_index(drop=True, inplace=True)\n",
    "CollectedMetrics.to_csv(fn_out, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
