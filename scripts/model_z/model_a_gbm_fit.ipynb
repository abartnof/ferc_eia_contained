{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4106c744-5a93-43c7-ae2c-fb55f0531ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6050b9ea-b35e-490e-906a-64e24aac85f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/model_a_training'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker'\n",
    "dir_working_model_a_training = os.path.join(data_dir, 'working_data/model_a/model_a_training')\n",
    "dir_working_model_a_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "725cdf07-49ce-4616-bd14-c9b5712563c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_x = os.path.join(dir_working_model_a_training, 'x.parquet')\n",
    "fn_y = os.path.join(dir_working_model_a_training, 'y.parquet')\n",
    "fn_id = os.path.join(dir_working_model_a_training, 'id.parquet')\n",
    "fn_model = os.path.join(dir_working_model_a_training, 'model_a_gbm.txt')\n",
    "# dir_hyperparameters = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train'\n",
    "# fn_out = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/gb_ray_tune/grid_search.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20fb90fd-594f-4e63-ba70-7edba9cd96f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_cleaning(X):\n",
    "    X = np.clip(X, a_min=-3, a_max=3)\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15e06971-c0e5-457b-862d-14be2ff7118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\n",
    "    'num_trees':482,\n",
    "    'learning_rate':0.0134,\n",
    "    'min_data_in_leaf':85,\n",
    "    'objective':'binary',\n",
    "    'early_stopping_round':-1,\n",
    "    'metrics':['binary_logloss', 'auc']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c284747-a577-4db4-a905-936af05dd97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_parquet(fn_x)\n",
    "Y = pd.read_parquet(fn_y)\n",
    "ID = pd.read_parquet(fn_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e57886-9622-4ed4-862a-1e8c69b7acbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is all done automagically by the R script that creates the new data tranches.\n",
    "# We only need to do this for the final model training\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(X)\n",
    "XClean = standard_scaler.transform(X)\n",
    "XClean = np_cleaning(XClean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e126458-7256-4e6b-b3f1-513527152e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6368, number of negative: 6368000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.346943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2854\n",
      "[LightGBM] [Info] Number of data points in the train set: 6374368, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000999 -> initscore=-6.907755\n",
      "[LightGBM] [Info] Start training from score -6.907755\n"
     ]
    }
   ],
   "source": [
    "train_set = lgb.Dataset(XClean, Y)\n",
    "gbm = lgb.train(\n",
    "        params = param_dict,\n",
    "        train_set=train_set   \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8019e65-7d53-4e71-bbb1-ee3225d36058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x468a06360>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.save_model(fn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e32dd9dd-76e7-4e7f-8a02-c57394a5d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: view the feature importances\n",
    "# pd.DataFrame({'importance':gbm.feature_importance(),\n",
    "#              'name':X.columns}).plot.barh(x='name', y='importance', figsize=[8, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "87caa34e-16e8-4b41-9a34-64cf0773ab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook model_a_gbm_fit.ipynb to script\n",
      "[NbConvertApp] Writing 3649 bytes to model_a_gbm_fit.py\n"
     ]
    }
   ],
   "source": [
    "# !jupyter nbconvert --to script model_a_gbm_fit.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
