{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e332e741-5388-43eb-b868-1d85938dbb35",
   "metadata": {},
   "source": [
    "# Get y-fits from model a ANN and GBM, which will be input for the stage 2 model\n",
    "\n",
    "__author__: Andrew Bartnof\n",
    "\n",
    "__copyright__: Copyright 2025, Rocky Mountain Institute\n",
    "\n",
    "__credits__: Alex Engel, Andrew Bartnof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f6e4028-f66d-47ff-a9c0-926cb5b61a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from keras import models, layers, regularizers, optimizers, callbacks, utils, losses, metrics\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow import convert_to_tensor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "860c5db0-9921-4588-8662-f2f127c1b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_cleaning(X):\n",
    "    X = np.clip(X, a_min=-3, a_max=3)\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5d3ae7a-2beb-4df0-acc7-d63141bd3725",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker'\n",
    "dir_working_model_a_training = os.path.join(data_dir, 'working_data/model_a/model_a_training')\n",
    "# dir_working_model_a_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3016c808-53b4-4418-8a92-8324af3baf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output file\n",
    "fn_y_fit_model_a = os.path.join(data_dir, 'working_data/model_z/y_fit_model_a.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58cb374b-4844-4a39-81ac-29e646a0761d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_x = os.path.join(dir_working_model_a_training, 'x.parquet')\n",
    "fn_y = os.path.join(dir_working_model_a_training, 'y.parquet')\n",
    "fn_id = os.path.join(dir_working_model_a_training, 'id.parquet')\n",
    "\n",
    "X = pd.read_parquet(fn_x)\n",
    "Y = pd.read_parquet(fn_y)\n",
    "ID = pd.read_parquet(fn_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9ec8a73-c802-4cf0-875b-2da8fed9b0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_model_a_ann = {\n",
    "    'dropout_1': 0.000120,\n",
    "    'dropout_2': 0.0633,\n",
    "    'relu_1': 33,\n",
    "    'relu_2': 20,\n",
    "    'epochs': 20\n",
    "}\n",
    "params_model_a_gbm = {\n",
    "    'num_trees':482,\n",
    "    'learning_rate':0.0134,\n",
    "    'min_data_in_leaf':85,\n",
    "    'objective':'binary',\n",
    "    'early_stopping_round':-1,\n",
    "    'metrics':['binary_logloss', 'auc']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c27fe-f56c-4290-acb0-b3a568bc1d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "\n",
    "for fold in tqdm(ID.fold.unique()):\n",
    "    \n",
    "    # Create Test and Train subsets based on fold num\n",
    "    is_train_mask = ID.fold != fold\n",
    "    XTrain = X.loc[is_train_mask]\n",
    "    XTest = X.loc[~is_train_mask]\n",
    "    \n",
    "    YTrain = Y.loc[is_train_mask]\n",
    "    YTest = Y.loc[~is_train_mask]\n",
    "    \n",
    "    # Clean the X datasets, based on the training data characteristics\n",
    "    standard_scaler = StandardScaler()\n",
    "    standard_scaler.fit(XTrain)\n",
    "    XTrain = standard_scaler.transform(XTrain)\n",
    "    XTest = standard_scaler.transform(XTest)\n",
    "    \n",
    "    XTrain = np_cleaning(XTrain)\n",
    "    XTest = np_cleaning(XTest)\n",
    "\n",
    "    # Fit models\n",
    "    # GBM\n",
    "    train_set = lgb.Dataset(XTrain, YTrain)\n",
    "    mod_a_gbm = lgb.train(\n",
    "            params = params_model_a_gbm,\n",
    "            train_set=train_set\n",
    "        )\n",
    "\n",
    "    # ANN\n",
    "    clear_session()\n",
    "    mod_a_ann = models.Sequential()\n",
    "    mod_a_ann.add(layers.Dropout(rate=params_model_a_ann[\"dropout_1\"]))\n",
    "    mod_a_ann.add(layers.Dense(units=params_model_a_ann[\"relu_1\"], activation='relu'))    \n",
    "    mod_a_ann.add(layers.Dropout(rate=params_model_a_ann[\"dropout_2\"]))\n",
    "    mod_a_ann.add(layers.Dense(units=params_model_a_ann[\"relu_2\"], activation='relu'))   \n",
    "    mod_a_ann.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    mod_a_ann.compile(\n",
    "        loss=losses.BinaryCrossentropy(),\n",
    "        metrics=[\n",
    "            metrics.BinaryCrossentropy(),\n",
    "            metrics.BinaryAccuracy(), \n",
    "            metrics.AUC()\n",
    "        ]\n",
    "    )\n",
    "        \n",
    "    history = mod_a_ann.fit(\n",
    "        XTrain, YTrain, epochs=params_model_a_ann['epochs'], batch_size=128,  # hard-coded here\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Make predictions\n",
    "    yfit_a_gbm = mod_a_gbm.predict(XTest)\n",
    "    \n",
    "    yfit_a_ann = mod_a_ann.predict(XTest)\n",
    "    yfit_a_ann = yfit_a_ann.reshape(-1,)\n",
    "\n",
    "    # Join ID to YFit, store together\n",
    "    RelevantID = ID.loc[~is_train_mask, ['record_id_ferc1', 'record_id_eia', 'fold']].reset_index(drop=True)\n",
    "\n",
    "    RelevantYFit = pd.DataFrame({\n",
    "        'y_fit_a_ann':yfit_a_ann,\n",
    "        'y_fit_a_gbm':yfit_a_gbm\n",
    "    })\n",
    "    \n",
    "    Results = pd.concat([RelevantID, RelevantYFit], axis=1)\n",
    "    results_list.append(Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c287b1c8-24fe-4aea-b03a-3f4c1ec2af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(results_list).reset_index(drop=True).to_parquet(fn_y_fit_model_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de6f5e4-662c-4ebc-a9c8-d07b5d8c806f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
