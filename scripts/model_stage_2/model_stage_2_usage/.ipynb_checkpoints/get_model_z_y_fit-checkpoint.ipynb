{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ce0631f-cf1a-4d4d-9f38-221a89513fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import lightgbm as lgb\n",
    "from tqdm.notebook import tqdm\n",
    "# from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bff1260e-9c44-4be6-a02c-99ea18d367ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker'\n",
    "\n",
    "dir_x_model_a = os.path.join(data_dir, 'working_data/model_a/model_a_x')\n",
    "dir_x_model_b = os.path.join(data_dir, 'working_data/model_b/model_b_x')\n",
    "\n",
    "dir_y_fit_model_a_ann = os.path.join(data_dir, 'working_data/model_a/model_a_ann_y_fit')\n",
    "dir_y_fit_model_a_gbm = os.path.join(data_dir, 'working_data/model_a/model_a_gbm_y_fit')\n",
    "\n",
    "dir_y_fit_model_b_ann = os.path.join(data_dir, 'working_data/model_b/model_b_ann_y_fit')\n",
    "dir_y_fit_model_b_gbm = os.path.join(data_dir, 'working_data/model_b/model_b_gbm_y_fit')\n",
    "\n",
    "dir_tranches = os.path.join(data_dir, 'working_data/tranches_ferc_to_eia')\n",
    "\n",
    "dir_y_fit_out = os.path.join(data_dir, 'working_data/model_second_stage/model_z_gbm_y_fit')\n",
    "\n",
    "fn_model2 = os.path.join(data_dir, 'working_data/model_second_stage/model_second_stage_training/model_2.txt')\n",
    "\n",
    "fn_top_one_mappings = os.path.join(data_dir, 'output_data/top_one_mappings.parquet')\n",
    "fn_top_ten_mappings = os.path.join(data_dir, 'output_data/top_ten_mappings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89d9c74d-d281-4a0f-a701-9f61b497f9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tranche_id(dir, colname):\n",
    "    # For any given directory, search for all the applicable parquet files, and\n",
    "    # return the results as a table with two columns, the parquet files (called whatever\n",
    "    # you input as colname), and the extracted tranche_id\n",
    "    # dir = dir_model_a\n",
    "    ff = glob(dir + '/*.parquet')\n",
    "    Cte = pd.DataFrame({colname:ff})\n",
    "    Cte['tranche_id'] = Cte[colname].str.extract('([0-9]{4}_[0-9]{3}(?=\\\\.parquet))')\n",
    "    Cte = Cte.set_index('tranche_id', drop=True)\n",
    "    return Cte\n",
    "\n",
    "def add_grouped_rank(ID, YFit):\n",
    "    # For any ID file and YFit file, return a table with y_fit and the ranks for the y_fits\n",
    "    Cte = ID[['record_id_ferc1']].copy()\n",
    "    Cte = pd.concat([Cte, YFit], axis=1)\n",
    "    Cte['y_fit_rank'] = Cte.groupby('record_id_ferc1')['y_fit'].rank(method='dense', ascending=False)\n",
    "    Cte = Cte[['y_fit', 'y_fit_rank']]\n",
    "    return Cte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bea601-ef03-4829-a699-11654a595205",
   "metadata": {},
   "source": [
    "Load model, locate all filenames and join them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9764b01c-993b-439b-b078-f63d817bf2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod2 = lgb.Booster(model_file=fn_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6476a993-da0e-4973-ba15-4a50561a9e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn_id</th>\n",
       "      <th>fn_x_a</th>\n",
       "      <th>fn_x_b</th>\n",
       "      <th>fn_y_fit_a_ann</th>\n",
       "      <th>fn_y_fit_a_gbm</th>\n",
       "      <th>fn_y_fit_b_ann</th>\n",
       "      <th>fn_y_fit_b_gbm</th>\n",
       "      <th>y_fit_out</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tranche_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001_000</th>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001_001</th>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "      <td>/Volumes/Extreme SSD/rematch_eia_ferc1_docker/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        fn_id  \\\n",
       "tranche_id                                                      \n",
       "2001_000    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "2001_001    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "\n",
       "                                                       fn_x_a  \\\n",
       "tranche_id                                                      \n",
       "2001_000    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "2001_001    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "\n",
       "                                                       fn_x_b  \\\n",
       "tranche_id                                                      \n",
       "2001_000    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "2001_001    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "\n",
       "                                               fn_y_fit_a_ann  \\\n",
       "tranche_id                                                      \n",
       "2001_000    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "2001_001    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "\n",
       "                                               fn_y_fit_a_gbm  \\\n",
       "tranche_id                                                      \n",
       "2001_000    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "2001_001    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "\n",
       "                                               fn_y_fit_b_ann  \\\n",
       "tranche_id                                                      \n",
       "2001_000    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "2001_001    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "\n",
       "                                               fn_y_fit_b_gbm  \\\n",
       "tranche_id                                                      \n",
       "2001_000    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "2001_001    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...   \n",
       "\n",
       "                                                    y_fit_out  \n",
       "tranche_id                                                     \n",
       "2001_000    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...  \n",
       "2001_001    /Volumes/Extreme SSD/rematch_eia_ferc1_docker/...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FN = pd.concat([\n",
    "        extract_tranche_id(dir=dir_tranches, colname='fn_id'),\n",
    "        extract_tranche_id(dir=dir_x_model_a, colname='fn_x_a'),\n",
    "        extract_tranche_id(dir=dir_x_model_b, colname='fn_x_b'),\n",
    "        extract_tranche_id(dir=dir_y_fit_model_a_ann, colname='fn_y_fit_a_ann'),\n",
    "        extract_tranche_id(dir=dir_y_fit_model_a_gbm, colname='fn_y_fit_a_gbm'),\n",
    "        extract_tranche_id(dir=dir_y_fit_model_b_ann, colname='fn_y_fit_b_ann'),\n",
    "        extract_tranche_id(dir=dir_y_fit_model_b_gbm, colname='fn_y_fit_b_gbm')\n",
    "    ], axis=1, join=\"outer\")\n",
    "\n",
    "# add location for output\n",
    "FN['y_fit_out'] = [os.path.join(dir_y_fit_out, 'model_z_gbm_y_fit__' + tranche_id + '.parquet') for tranche_id in FN.index.values]\n",
    "\n",
    "FN.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125d85f2-e46f-4d38-bb05-8d0a214e37c4",
   "metadata": {},
   "source": [
    "The input for this model should look like this:\n",
    "- X encoding A\n",
    "- X encoding B\n",
    "- y-fit, y-fit ranks from ANN A\n",
    "- y-fit, y-fit ranks from GBM A\n",
    "- y-fit, y-fit ranks from ANN B\n",
    "- y-fit, y-fit ranks from GBM B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098cfe99-f333-424a-a93f-5d8161b20b56",
   "metadata": {},
   "source": [
    "# Iterate through tranches and get fitted values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6cc96-e4b9-4344-a258-d28e555879d3",
   "metadata": {},
   "source": [
    "For each row in the FN table, note the top 20 mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fd1758e-fee1-47de-996d-206c3c2359c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06805bdf364346d58c501bc5681de493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_mapping_dict = {tranche:None for tranche in FN.index.values}\n",
    "\n",
    "for index, row in tqdm( FN.iterrows(), total=len(FN) ):\n",
    "    \n",
    "    ID = pd.read_parquet(row['fn_id'])\n",
    "    X1A = pd.read_parquet(row['fn_x_a'])\n",
    "    X1B = pd.read_parquet(row['fn_x_b'])\n",
    "    YFit1AAnn = pd.read_parquet(row['fn_y_fit_a_ann'])\n",
    "    YFit1AGbm = pd.read_parquet(row['fn_y_fit_a_gbm'])\n",
    "    YFit1BAnn = pd.read_parquet(row['fn_y_fit_b_ann'])\n",
    "    YFit1BGbm = pd.read_parquet(row['fn_y_fit_b_gbm'])\n",
    "    \n",
    "    X = np.hstack((\n",
    "        X1A.values, \n",
    "        X1B.values,\n",
    "        add_grouped_rank(ID=ID, YFit=YFit1AAnn).values,\n",
    "        add_grouped_rank(ID=ID, YFit=YFit1AGbm).values,\n",
    "        add_grouped_rank(ID=ID, YFit=YFit1BAnn).values,\n",
    "        add_grouped_rank(ID=ID, YFit=YFit1BGbm).values\n",
    "    ))\n",
    "    \n",
    "    y_fit2 = mod2.predict(X)\n",
    "    \n",
    "    ID = ID\n",
    "    Cte = ID.copy()\n",
    "    Cte['y_fit'] = y_fit2\n",
    "    Cte['y_fit_rank'] = Cte.groupby('record_id_ferc1')['y_fit'].rank(method='dense', ascending=False)\n",
    "    OutputYFitRank = Cte[['y_fit', 'y_fit_rank']]\n",
    "\n",
    "    # Write each tranche's y-fit to disk-- then collect top mappings in a dictionary\n",
    "    OutputYFitRank.to_parquet(path=row['y_fit_out'], index=False) \n",
    "    \n",
    "    TopMappings = Cte.sort_values(['record_id_ferc1', 'y_fit'], ascending=False).groupby('record_id_ferc1').head(20).reset_index(drop=True)    \n",
    "    top_mapping_dict[index] = TopMappings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edfe81b-bd6a-4349-a2a0-67bc0a7c7ad5",
   "metadata": {},
   "source": [
    "Save two files-- the top match only, and the top 10 matches, jic someone needs to poke around and find some good alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce6ceb11-7a22-4572-b4c6-a40c65863cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "TopMappings = pd.concat(top_mapping_dict.values(), axis=0).reset_index(drop=True)\n",
    "TopMappings = TopMappings.sort_values(['record_id_ferc1', 'y_fit', 'record_id_eia'], ascending=[True, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19830210-cb05-4cb9-a5b3-931955d1088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TopOne = TopMappings.groupby('record_id_ferc1').head(1).reset_index(drop=True)\n",
    "TopTen = TopMappings.groupby('record_id_ferc1').head(10).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "568967bb-02d7-48ed-8d0c-3d48f744a1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TopOne.to_parquet(fn_top_one_mappings)\n",
    "TopTen.to_parquet(fn_top_ten_mappings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
