{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4106c744-5a93-43c7-ae2c-fb55f0531ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, auc, precision_score, recall_score, roc_auc_score, log_loss\n",
    "from tqdm.notebook import tqdm\n",
    "import itertools\n",
    "\n",
    "# import dask\n",
    "# from ray import train, tune\n",
    "# from ray.tune.search.optuna import OptunaSearch\n",
    "# from ray.tune.s|chedulers import ASHAScheduler\n",
    "# from ray.tune.search import ConcurrencyLimiter\n",
    "# from optuna.samplers import TPESampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "725cdf07-49ce-4616-bd14-c9b5712563c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_train_x = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/train_x.parquet'\n",
    "fn_train_y = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/train_y.parquet'\n",
    "\n",
    "fn_test_x = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/test_x.parquet'\n",
    "fn_test_y = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/test_y.parquet'\n",
    "\n",
    "fn_train_id = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/train_id.parquet'\n",
    "fn_test_id = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/test_id.parquet'\n",
    "\n",
    "fn_grid = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/gb_ray_tune/grid_search.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d98222c-0a30-4993-8f5e-769f0a944d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainX = pd.read_parquet(fn_train_x)\n",
    "TrainY = pd.read_parquet(fn_train_y)\n",
    "TestX = pd.read_parquet(fn_test_x)\n",
    "TestY = pd.read_parquet(fn_test_y)\n",
    "TrainID = pd.read_parquet(fn_train_id)\n",
    "TestID = pd.read_parquet(fn_test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23cb7515-ae11-42b4-8f34-170219e22678",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([TrainX, TestX])\n",
    "Y = pd.concat([TrainY, TestY])\n",
    "ID = pd.concat([TrainID, TestID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d39c5999-4d71-43cc-b2a9-9be29c4849c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_trees': 437,\n",
       " 'learning_rate': 0.0076861305642603,\n",
       " 'min_data_in_leaf': 76,\n",
       " 'objective': 'binary',\n",
       " 'early_stopping_round': -1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename_dict = {'config/num_trees':'num_trees', 'config/learning_rate':'learning_rate', 'config/min_data_in_leaf':'min_data_in_leaf', 'config/objective':'objective', 'config/early_stopping_round':'early_stopping_round'} #, 'config/metrics':'metrics'}\n",
    "\n",
    "Grid = pd.read_csv(fn_grid, index_col='rank')\n",
    "Grid = Grid.rename(columns=rename_dict)[list(rename_dict.values())]\n",
    "\n",
    "# Create a dictionary: punch in the rank of the model we want to use, and get the parameters back, as a dictionary\n",
    "param_dict = {i:Grid.loc[i].to_dict() for i in Grid.index}\n",
    "param_dict[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f41c5098-537b-438e-9668-b8ecc7a0090f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('f1_steam_2005_12_108_0_1', 1),\n",
       " ('f1_steam_2005_12_108_0_2', 0),\n",
       " ('f1_steam_2005_12_108_0_4', 2),\n",
       " ('f1_steam_2005_12_108_0_5', 0),\n",
       " ('f1_steam_2005_12_108_1_1', 4)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assign a number, 0-4, for each unique ferc id\n",
    "\n",
    "unique_ferc_ids = ID['record_id_ferc1'].unique()\n",
    "num_folds = 5\n",
    "fold_list = np.random.choice(a=range(num_folds), size=len(unique_ferc_ids))\n",
    "id_to_fold_dict = dict(zip(unique_ferc_ids.tolist(), fold_list))\n",
    "\n",
    "list(id_to_fold_dict.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1cc802-2b32-4ee2-b369-064ec6e06b0e",
   "metadata": {},
   "source": [
    "Each record_id_ferc1 is mapped to a number, 0:num_folds. \n",
    "\n",
    "This means that for any fold, we can say that any record_id_ferc1 that corresponds to that number is testing data, and all others are training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f044d86-2d54-4524-bee1-cb181a8c742d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1501d8e2893a49beb951ee61f567a5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5037, number of negative: 10074000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.521521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2907\n",
      "[LightGBM] [Info] Number of data points in the train set: 10079037, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000500 -> initscore=-7.600902\n",
      "[LightGBM] [Info] Start training from score -7.600902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5090, number of negative: 10180000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.642715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2910\n",
      "[LightGBM] [Info] Number of data points in the train set: 10185090, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000500 -> initscore=-7.600902\n",
      "[LightGBM] [Info] Start training from score -7.600902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5037, number of negative: 10074000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.636829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2907\n",
      "[LightGBM] [Info] Number of data points in the train set: 10079037, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000500 -> initscore=-7.600902\n",
      "[LightGBM] [Info] Start training from score -7.600902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5090, number of negative: 10180000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.556522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2910\n",
      "[LightGBM] [Info] Number of data points in the train set: 10185090, number of used features: 57\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000500 -> initscore=-7.600902\n",
      "[LightGBM] [Info] Start training from score -7.600902\n"
     ]
    }
   ],
   "source": [
    "variables = [\n",
    "    range(2),  # num hyperparameters to test\n",
    "    range(2)\n",
    "    # range(num_folds)  # number of folds per test\n",
    "]\n",
    "\n",
    "y_fit_list = []\n",
    "for (hp_rank, fold) in tqdm(list(itertools.product(*variables))):\n",
    "\n",
    "    # Split into training and test sets, based on the id_to_fold_dict mapping to the ID array\n",
    "    is_training_data_mask = [ id_to_fold_dict[id]!=fold for id in ID['record_id_ferc1'] ]\n",
    "    is_training_data_mask = np.array(is_training_data_mask)\n",
    "    \n",
    "    train_set = lgb.Dataset(X.loc[is_training_data_mask], Y.loc[is_training_data_mask])\n",
    "    XTest = X.loc[~is_training_data_mask]\n",
    "    YTest = Y.loc[~is_training_data_mask]\n",
    "    \n",
    "    mod_fit = lgb.train(params=param_dict[hp_rank], train_set=train_set)\n",
    "    y_fit = mod_fit.predict(XTest)\n",
    "    # Test = lgb.Dataset(X.loc[~is_training_data_mask], Y.loc[~is_training_data_mask])\n",
    "    \n",
    "    Framework = ID[~is_training_data_mask].copy()\n",
    "    Framework['y_true'] = YTest['is_match']\n",
    "    Framework['y_fit'] = y_fit\n",
    "\n",
    "    Framework = Framework[['record_id_ferc1', 'y_fit', 'y_true']]\n",
    "    Framework['model_num'] = hp_rank\n",
    "    Framework['fold_num'] = fold\n",
    "    y_fit_list.append(Framework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "eac8ae07-4ee6-4463-9844-a1e6cbd44eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_num</th>\n",
       "      <th>fold_num</th>\n",
       "      <th>record_id_ferc1</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_fit</th>\n",
       "      <th>y_fit_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f1_steam_2005_12_108_0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f1_steam_2005_12_108_0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f1_steam_2005_12_108_0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f1_steam_2005_12_108_0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>f1_steam_2005_12_108_0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_num  fold_num           record_id_ferc1  y_true     y_fit  y_fit_adj\n",
       "0          0         0  f1_steam_2005_12_108_0_1       0  0.000017          0\n",
       "1          0         0  f1_steam_2005_12_108_0_1       0  0.000017          0\n",
       "2          0         0  f1_steam_2005_12_108_0_1       0  0.000015          0\n",
       "3          0         0  f1_steam_2005_12_108_0_1       0  0.000017          0\n",
       "4          0         0  f1_steam_2005_12_108_0_1       0  0.000024          0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AggYFit = pd.concat(y_fit_list).reset_index(drop=True)\n",
    "\n",
    "AggYFit['groupwise_max_y_fit'] = AggYFit.groupby('record_id_ferc1')['y_fit'].transform('max')\n",
    "AggYFit['y_fit_adj'] = AggYFit['y_fit'] == AggYFit['groupwise_max_y_fit']\n",
    "AggYFit['y_fit_adj'] = 1 * AggYFit['y_fit_adj']\n",
    "AggYFit = AggYFit[['model_num', 'fold_num', 'record_id_ferc1', 'y_true', 'y_fit', 'y_fit_adj']]\n",
    "AggYFit.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
