{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4106c744-5a93-43c7-ae2c-fb55f0531ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from ray import train, tune\n",
    "# from ray.tune.search.optuna import OptunaSearch\n",
    "# from ray.tune.s|chedulers import ASHAScheduler\n",
    "# from ray.tune.search import ConcurrencyLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "725cdf07-49ce-4616-bd14-c9b5712563c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_train_x = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/train_x.parquet'\n",
    "fn_train_y = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/train_y.parquet'\n",
    "fn_train_id = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/test_id.parquet'\n",
    "# dir_hyperparameters = '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b546ac-71fe-4173-9aee-38ab32f785fa",
   "metadata": {},
   "source": [
    "Demonstrate model goodness-of-fit statistics\n",
    "\n",
    "NB- each time raytune runs, it uses a different subset of the data- so the hyperparameter search (and its resulting AUCs and binary logloss metrics) were _not_ subject to leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50c44653-ddd4-43b2-8e8f-ba68ea68a5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_parquet(fn_train_x)\n",
    "Y = pd.read_parquet(fn_train_y)\n",
    "ID = pd.read_parquet(fn_train_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "02ab352f-d6dd-47b2-8f1e-6713c3e6d2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "record_id_ferc1\n",
       "f1_steam_2005_12_210_1_3    467\n",
       "f1_hydro_2012_12_57_1_5     464\n",
       "f1_steam_2016_12_99_0_4     464\n",
       "f1_hydro_2019_12_186_0_2    463\n",
       "f1_steam_2017_12_70_0_1     460\n",
       "                           ... \n",
       "f1_steam_2014_12_57_1_5     338\n",
       "f1_hydro_2005_12_134_1_2    337\n",
       "f1_steam_2004_12_6_0_1        1\n",
       "f1_steam_2004_12_79_1_5       1\n",
       "f1_steam_2004_12_44_5_1       1\n",
       "Name: count, Length: 8024, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID.record_id_ferc1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94d16529-2618-4613-939e-ad0deb62c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "fold_array = np.random.choice(a=range(num_folds), size=X.shape[0], replace=True)\n",
    "params = {'learning_rate':0.0160, 'min_data_in_leaf':163, 'num_iterations':450}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f73ffa6d-b5a7-4488-94f0-edcc3e10c38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.627447 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2895\n",
      "[LightGBM] [Info] Number of data points in the train set: 10270983, number of used features: 57\n",
      "[LightGBM] [Info] Start training from score 0.000500\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "is_train_mask = fold_array != fold\n",
    "\n",
    "train_set = lgb.Dataset(X.loc[is_train_mask], Y.loc[is_train_mask])\n",
    "# test_set = lgb.Dataset(X.loc[~is_train_mask], Y.loc[~is_train_mask])\n",
    "\n",
    "mod_fit = lgb.train(train_set=train_set, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8706fbd-b27f-4687-80ae-2e3dd7d497bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.81124201e-05,  2.91890802e-05, -7.90502318e-05, ...,\n",
       "       -1.45751114e-05,  2.61739336e-04,  2.39382389e-04])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_fit.predict(X.loc[~is_train_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbe7ee40-8d8e-4f21-9477-69795210dd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_mod(space):\n",
    "\n",
    "    # ELT\n",
    "    X = pd.read_parquet(fn_train_x)\n",
    "    Y = pd.read_parquet(fn_train_y)\n",
    "    # X = pd.read_parquet('/Volumes/Extreme SSD/rematch1_predictor/full_training_data/train_x.parquet')\n",
    "    # Y = pd.read_parquet('/Volumes/Extreme SSD/rematch1_predictor/full_training_data/full_data_y.parquet')\n",
    "    \n",
    "    size_of_train_set = round(0.8 * X.shape[0])\n",
    "    rows_for_train_set = np.random.choice(a=X.index, size=size_of_train_set, replace=False)\n",
    "    rows_for_val_set = np.setdiff1d(X.index, rows_for_train_set)\n",
    "    \n",
    "    train_set = lgb.Dataset(X.loc[rows_for_train_set], Y.loc[rows_for_train_set])\n",
    "    val_set = lgb.Dataset(X.loc[rows_for_val_set], Y.loc[rows_for_val_set])\n",
    "\n",
    "    # Model\n",
    "    gbm = lgb.train(\n",
    "        space,\n",
    "        train_set,\n",
    "        valid_sets=[val_set],\n",
    "    )\n",
    "    binary_logloss = gbm.best_score['valid_0']['binary_logloss']\n",
    "    auc = gbm.best_score['valid_0']['auc']\n",
    "    train.report(\n",
    "        {\n",
    "            \"binary_logloss\": binary_logloss,\n",
    "            \"auc\": auc\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c205b97-589d-4eac-a8a5-78e63fbdfd9e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tune' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m space \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_iterations\u001b[39m\u001b[38;5;124m'\u001b[39m: tune\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m500\u001b[39m),\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# 'num_rounds': tune.randint(1, 500),\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m: tune\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.0001\u001b[39m, \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_data_in_leaf\u001b[39m\u001b[38;5;124m'\u001b[39m: tune\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m200\u001b[39m),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# 'early_stopping_round':2,\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetrics\u001b[39m\u001b[38;5;124m'\u001b[39m:[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_logloss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauc\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m     }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tune' is not defined"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'num_iterations': tune.randint(1, 500),\n",
    "    # 'num_rounds': tune.randint(1, 500),\n",
    "    'learning_rate': tune.uniform(0.0001, 1),\n",
    "    'min_data_in_leaf': tune.randint(1, 200),\n",
    "    'objective':'binary', \n",
    "    # 'early_stopping_round':2,\n",
    "    'metrics':['binary_logloss', 'auc']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "874491e2-bdab-4591-8651-ec4635185a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asha_scheduler = ASHAScheduler(\n",
    "#     time_attr='training_iteration',\n",
    "#     metric='binary_logloss',\n",
    "#     mode='min',\n",
    "#     max_t=1000,\n",
    "#     grace_period=50,\n",
    "#     reduction_factor=3,\n",
    "#     brackets=1,\n",
    "# )\n",
    "\n",
    "search_alg = OptunaSearch(metric=\"binary_logloss\", mode=\"min\")\n",
    "search_alg = ConcurrencyLimiter(search_alg, max_concurrent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a258cd81-5cb2-4fae-bc80-0fdcd4225b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-12-17 20:25:39</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:32.58        </td></tr>\n",
       "<tr><td>Memory:      </td><td>6.7/8.0 GiB        </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name      </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  min_data_in_leaf</th><th style=\"text-align: right;\">  num_rounds</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>fit_mod_92a66e20</td><td>RUNNING </td><td>127.0.0.1:28623</td><td style=\"text-align: right;\">       0.826715</td><td style=\"text-align: right;\">               159</td><td style=\"text-align: right;\">         138</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=28623)\u001b[0m /opt/miniconda3/lib/python3.12/site-packages/dask/dataframe/__init__.py:31: FutureWarning: \n",
      "\u001b[36m(pid=28623)\u001b[0m Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\u001b[36m(pid=28623)\u001b[0m \n",
      "\u001b[36m(pid=28623)\u001b[0m You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "\u001b[36m(pid=28623)\u001b[0m This will raise in a future version.\n",
      "\u001b[36m(pid=28623)\u001b[0m \n",
      "\u001b[36m(pid=28623)\u001b[0m   warnings.warn(msg, FutureWarning)\n",
      "\u001b[36m(fit_mod pid=28623)\u001b[0m /opt/miniconda3/lib/python3.12/site-packages/lightgbm/engine.py:204: UserWarning: Found `num_rounds` in params. Will use it instead of argument\n",
      "\u001b[36m(fit_mod pid=28623)\u001b[0m   _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "2024-12-17 20:25:39,561\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2024-12-17 20:25:39,591\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/gb_ray_tune' in 0.0191s.\n",
      "2024-12-17 20:25:49,691\tINFO tune.py:1041 -- Total run time: 42.71 seconds (32.56 seconds for the tuning loop).\n",
      "2024-12-17 20:25:49,697\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/Volumes/Extreme SSD/rematch_eia_ferc1_docker/working_data/model_a/train/gb_ray_tune\", trainable=...)\n"
     ]
    }
   ],
   "source": [
    "tuner = tune.Tuner(\n",
    "    fit_mod,\n",
    "    tune_config=tune.TuneConfig(\n",
    "        # scheduler=asha_scheduler,\n",
    "        search_alg=search_alg,\n",
    "        num_samples=1000\n",
    "    ),\n",
    "    param_space=space,\n",
    "    run_config=train.RunConfig(\n",
    "        storage_path=dir_hyperparameters, \n",
    "        name=\"gb_ray_tune\"\n",
    "    )\n",
    ")\n",
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0530a636-edca-466d-bd97-2cc743cafdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_path = \"/Users/andrewbartnof/Documents/rmi/rematch_ferc_eia1/clean_data/model_full_gradient_boost/ray_tune/gb_ray_tune\"\n",
    "# restored_tuner = tune.Tuner.restore(experiment_path, trainable=fit_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c865454-c5f1-452f-a4eb-a0b46be8f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fn_results = '/Users/andrewbartnof/Documents/rmi/rematch_ferc_eia1/clean_data/model_full_gradient_boost/ray_tune/ray_tune_dataframe.csv'\n",
    "# restored_tuner.get_results().get_dataframe().to_csv(fn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87caa34e-16e8-4b41-9a34-64cf0773ab49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook model_a_hyperparameter_search.ipynb to script\n",
      "[NbConvertApp] Writing 3141 bytes to model_a_hyperparameter_search.py\n"
     ]
    }
   ],
   "source": [
    "# !jupyter nbconvert --to script model_a_hyperparameter_search.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
